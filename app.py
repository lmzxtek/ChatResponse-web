import numpy as np
import os
import re
import datetime
import time
import openai, tenacity
import argparse
import configparser
import json
import tiktoken
from get_paper_from_pdf import Paper
import gradio

# å®šä¹‰Responseç±»
class Response:
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®å±æ€§
    def __init__(self, api, comment, language):
        self.api = api
        self.comment = comment
        self.language = language     
        self.max_token_num = 4096
        self.encoding = tiktoken.get_encoding("gpt2")
    
    
    @tenacity.retry(wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
                    stop=tenacity.stop_after_attempt(5),
                    reraise=True)
    def chat_response(self):
        openai.api_key = self.api
        response_prompt_token = 1000        
        text_token = len(self.encoding.encode(self.comment))
        input_text_index = int(len(self.comment)*(self.max_token_num-response_prompt_token)/text_token)
        input_text = "This is the review comments:" + self.comment[:input_text_index]
        messages=[
                {"role": "system", "content": """You are the author, you submitted a paper, and the reviewers gave the review comments. 
                Please reply with what we have done, not what we will do.
                You need to extract questions from the review comments one by one, and then respond point-to-point to the reviewersâ€™ concerns. 
                Must be output in {}. Follow the format of the output later: 
                - Response to reviewers
                #1 reviewer
                Concern #1: xxxx
                Author response: xxxxx
                Concern #2: xxxx
                Author response: xxxxx
                ...
                #2 reviewer
                Concern #1: xxxx
                Author response: xxxxx
                Concern #2: xxxx
                Author response: xxxxx
                ...
                #3 reviewer
                Concern #1: xxxx
                Author response: xxxxx
                Concern #2: xxxx
                Author response: xxxxx
                ...
                
                """.format(self.language)
 
                },
                {"role": "user", "content": input_text},
            ]
                
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages,
        )
        result = ''
        for choice in response.choices:
            result += choice.message.content
        print("********"*10)
        print(result)
        print("********"*10)
        print("prompt_token_used:", response.usage.prompt_tokens)
        print("completion_token_used:", response.usage.completion_tokens)
        print("total_token_used:", response.usage.total_tokens)
        print("response_time:", response.response_ms/1000.0, 's')                    
        return result, response.usage.total_tokens
                        
                           

def main(api, comment, language):  
    start_time = time.time()
    if not api or not comment:
        return "è¯·è¾“å…¥API-keyä»¥åŠå®¡ç¨¿æ„è§ï¼"
    else:
        Response1 = Response(api, comment, language)
        # å¼€å§‹åˆ¤æ–­æ˜¯è·¯å¾„è¿˜æ˜¯æ–‡ä»¶ï¼š   
        response, total_token_used = Response1.chat_response()
    time_used = time.time() - start_time
    output2 ="ä½¿ç”¨tokenæ•°ï¼š"+ str(total_token_used)+"\nèŠ±è´¹æ—¶é—´ï¼š"+ str(round(time_used, 2)) +"ç§’"
    return response, output2
        

########################################################################################################    
# æ ‡é¢˜
title = "ğŸ¤–ChatResponseğŸ¤–"
# æè¿°

description = '''<div align='left'>
<img align='right' src='http://i.imgtg.com/2023/03/22/94PLN.png' width="220">

<strong>ChatResponseæ˜¯ä¸€æ¬¾æ ¹æ®å®¡ç¨¿äººçš„è¯„è®ºè‡ªåŠ¨ç”Ÿæˆä½œè€…å›å¤çš„AIåŠ©æ‰‹ã€‚</strong>å…¶ç”¨é€”ä¸ºï¼š

â­ï¸æ ¹æ®è¾“å…¥çš„å®¡ç¨¿æ„è§ï¼ŒChatResponseä¼šè‡ªåŠ¨æå–å…¶ä¸­å„ä¸ªå®¡ç¨¿äººçš„é—®é¢˜å’Œæ‹…å¿§ï¼Œå¹¶ç”Ÿæˆç‚¹å¯¹ç‚¹çš„å›å¤ã€‚

å¦‚æœè§‰å¾—å¾ˆå¡ï¼Œå¯ä»¥ç‚¹å‡»å³ä¸Šè§’çš„Duplicate this Spaceï¼ŒæŠŠChatResponseå¤åˆ¶åˆ°ä½ è‡ªå·±çš„Spaceä¸­ï¼

æœ¬é¡¹ç›®çš„[Github](https://github.com/nishiwen1214/ChatResponse)ï¼Œæ¬¢è¿Starå’ŒForkï¼Œä¹Ÿæ¬¢è¿å¤§ä½¬èµåŠ©è®©æœ¬é¡¹ç›®å¿«é€Ÿæˆé•¿ï¼ğŸ’—ï¼ˆ[è·å–Api Key](https://chatgpt.cn.obiscr.com/blog/posts/2023/How-to-get-api-key/)ï¼‰
</div>
'''

# åˆ›å»ºGradioç•Œé¢
inp = [gradio.inputs.Textbox(label="è¯·è¾“å…¥ä½ çš„API-key(skå¼€å¤´çš„å­—ç¬¦ä¸²)",
                          default="",
                          type='password'),
    gradio.inputs.Textbox(lines=5,
        label="è¯·è¾“å…¥è¦å›å¤çš„å®¡ç¨¿æ„è§",
        default=""
    ),
    gradio.inputs.Radio(choices=["English", "Chinese"],
                        default="English",
                        label="é€‰æ‹©è¾“å‡ºè¯­è¨€"),
]

chat_Response_gui = gradio.Interface(fn=main,
                                 inputs=inp,
                                 outputs = [gradio.Textbox(lines=11, label="å›å¤ç»“æœ"), gradio.Textbox(lines=2, label="èµ„æºç»Ÿè®¡")],
                                 title=title,
                                 description=description)

# Start server
chat_Response_gui .launch(quiet=True, show_api=False)